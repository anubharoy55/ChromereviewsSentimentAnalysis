{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd62383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import csv\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "class ChromeReviewsSentimentAnalysisCopy:\n",
    "    def fileOperations(df1):\n",
    "\n",
    "        df1 = pd.read_csv(\"chrome_reviews.csv\")\n",
    "\n",
    "        df=df1.dropna(subset=['Text'], inplace=False)\n",
    "        df=df.reset_index()\n",
    "\n",
    "    # Get the number of reviews based on the df cloumn size\n",
    "        num_reviews = df['Text'].size\n",
    "\n",
    "    # Initialise an empty list to hold the clean reviews\n",
    "        cleaned_reviews = []\n",
    "\n",
    "    # Loop over each review; create an index i that goes from 0 to the length\n",
    "    # of the movie review list\n",
    "        for i in range(0, num_reviews):\n",
    "        # call our function for each one, and add the result to the list of\n",
    "        # clean reviews\n",
    "        #print(df['Text'][i])\n",
    "            cleaned_reviews.append(review_to_words(df['Text'][i]))\n",
    "\n",
    "        df['Cleaned Reviews']=cleaned_reviews\n",
    "        print('In file operations')\n",
    "        output=analyzerFunc(df)\n",
    "        return output\n",
    "\n",
    "    def remove_emoji(string):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   u\"\\U0001f926-\\U0001f937\"\n",
    "                                   u\"\\U00010000-\\U0010ffff\"\n",
    "                                   u\"\\u2640-\\u2642\"\n",
    "                                   u\"\\u2600-\\u2B55\"\n",
    "                                   u\"\\u200d\"\n",
    "                                   u\"\\u23cf\"\n",
    "                                   u\"\\u23e9\"\n",
    "                                   u\"\\u231a\"\n",
    "                                   u\"\\ufe0f\"  # dingbats\n",
    "                                   u\"\\u3030\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        #print('In emoji remover')\n",
    "        return emoji_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "    def review_to_words( raw_review ):\n",
    "\n",
    "        #. Remove non letters\n",
    "        current=remove_emoji(raw_review)\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", current)\n",
    "\n",
    "        words = letters_only.lower().split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        stops.remove('no')\n",
    "        stops.remove('not')\n",
    "\n",
    "        meaningful_words = []\n",
    "        for token in words:\n",
    "            if token not in stops:\n",
    "                token= lemmatizer.lemmatize(token)\n",
    "                meaningful_words.append(token)\n",
    "                    #print('\\nNext Token : ',token)\n",
    "        #print('In reviews to words')\n",
    "        return \" \".join(meaningful_words)\n",
    "\n",
    "\n",
    "\n",
    "    def analyzerFunc(df):\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        with open('GoodReviewsBadRating.csv','w',encoding=\"utf-8\") as f:\n",
    "            writer=csv.writer(f)\n",
    "            writer.writerow(df.columns)\n",
    "            for i in range(0,df['Text'].size):\n",
    "                if (sia.polarity_scores(df['Cleaned Reviews'][i])['compound']>0.3 and sia.polarity_scores(df['Cleaned Reviews'][i])['neu']<0.3 and sia.polarity_scores(df['Cleaned Reviews'][i])['pos']>0.68 and df['Star'][i]==1):#in positiveWords and df['Star'][i]<2:\n",
    "                    #print('\\n',df.iloc[i],'\\n')\n",
    "                    writer.writerow(df.iloc[i])\n",
    "                    #print(sia.polarity_scores(df['Cleaned Reviews'][i]))\n",
    "\n",
    "        df.drop('Cleaned Reviews',axis=1,inplace=True)\n",
    "        output=[]\n",
    "        df2 = pd.read_csv(\"GoodReviewsBadRating.csv\")\n",
    "        for i in range(0,df2['Text'].size):\n",
    "            output.append(df2.iloc[i])\n",
    "        #print(output)\n",
    "        #print('In analyzaer')\n",
    "        return output\n",
    "\n",
    "                                #df2=pd.read_csv('GoodReviewsBadRating.csv')\n",
    "        \n",
    "import pickle\n",
    "pickle_out = open(\"classifier.pkl\", mode = \"wb\")\n",
    "pickle.dump(ChromeReviewsSentimentAnalysisCopy\n",
    ", pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97093465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"classifier.pkl\", mode = \"wb\")\n",
    "pickle.dump(fileOperations\n",
    ", pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dfece9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
